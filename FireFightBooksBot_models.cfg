#embedmodel: 'nomic-embed-text'
embedmodel: 'navec'
#mainmodel: 'gemma:2b'
mainmodel: 'llama3.1'
collection_name: 'fire_fight'
reference_docs_path: './knowlege/fire_fight' # Select folder with reference docs. 
chunking: 'by_tags' # 'by_sentences' method of chunking.  
begin_tag: 'source:' # Select reference text separator.
use_chat: False  # Selects chat mode of model, if False generator mode is used.
print_context: True  # Print context which wil be added to prompt. 
base_for_prompt: "You consultant for fire fighting safety" \
              "Answer in Russian to question:  <user_query>." \
              " Every time point source, chapter number and page number" \
              " where answer info was found." \
              " In answer use point as a decimal separator in float point numbers." \
              " Limit answer length by four sentences." \
              " Use as reference a following text from safety manual:" \
              "<rag_context>"