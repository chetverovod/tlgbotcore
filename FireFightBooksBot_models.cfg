#embedmodel: 'nomic-embed-text'
embedmodel: 'navec'
#mainmodel: 'gemma:2b'
mainmodel: 'llama3.1'
chroma_port: 8000
collection_name: 'fire_fight'
reference_docs_path: './knowlege/fire_fight' # Select folder with reference docs. 
chunking: 'by_tags' # 'by_sentences' method of chunking.  
split_by_paragraphs: True
begin_tag: '<paragraph>' # Select reference text paragraph separator.
# use_chat: False  # Selects chat mode of model, if False generator mode is used.
use_chat: True  # Selects chat mode of model, if False generator mode is used.
print_context: False # True  # Print context which wil be added to prompt. 
base_for_prompt: "You are consultant for fire fighting safety" \
              " Answer in Russian to question:  <user_query>." \
              " Every time point source, chapter number and page number" \
              " where answer info was found." \
              " Use three sentences maximum and keep the answer as concise as possible." \
              "\nYour previous conversation with user is in this list <conversation_history>\n" \
              "\nUse as reference a following text from safety manual:" \
              "<rag_context>"